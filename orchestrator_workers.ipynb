{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional\n",
    "from util import llm_call, extract_xml\n",
    "\n",
    "def parse_tasks(tasks_xml: str) -> List[Dict]:\n",
    "    \"\"\"Parse XML tasks into a list of task dictionaries.\"\"\"\n",
    "    tasks = []\n",
    "    current_task = {}\n",
    "    \n",
    "    for line in tasks_xml.split('\\n'):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "            \n",
    "        if line.startswith(\"<task>\"):\n",
    "            current_task = {}\n",
    "        elif line.startswith(\"<type>\"):\n",
    "            current_task[\"type\"] = line[6:-7].strip()\n",
    "        elif line.startswith(\"<description>\"):\n",
    "            current_task[\"description\"] = line[12:-13].strip()\n",
    "        elif line.startswith(\"</task>\"):\n",
    "            if \"description\" in current_task:\n",
    "                if \"type\" not in current_task:\n",
    "                    current_task[\"type\"] = \"default\"\n",
    "                tasks.append(current_task)\n",
    "    \n",
    "    return tasks\n",
    "\n",
    "class FlexibleOrchestrator:\n",
    "    \"\"\"Break down tasks and run them in parallel using worker LLMs.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        orchestrator_prompt: str,\n",
    "        worker_prompt: str,\n",
    "    ):\n",
    "        \"\"\"Initialize with prompt templates.\"\"\"\n",
    "        self.orchestrator_prompt = orchestrator_prompt\n",
    "        self.worker_prompt = worker_prompt\n",
    "\n",
    "    def _format_prompt(self, template: str, **kwargs) -> str:\n",
    "        \"\"\"Format a prompt template with variables.\"\"\"\n",
    "        try:\n",
    "            return template.format(**kwargs)\n",
    "        except KeyError as e:\n",
    "            raise ValueError(f\"Missing required prompt variable: {e}\")\n",
    "\n",
    "    def process(self, task: str, context: Optional[Dict] = None) -> Dict:\n",
    "        \"\"\"Process task by breaking it down and running subtasks in parallel.\"\"\"\n",
    "        context = context or {}\n",
    "        \n",
    "        # Step 1: Get orchestrator response\n",
    "        orchestrator_input = self._format_prompt(\n",
    "            self.orchestrator_prompt,\n",
    "            task=task,\n",
    "            **context\n",
    "        )\n",
    "        orchestrator_response = llm_call(orchestrator_input)\n",
    "        \n",
    "        # Parse orchestrator response\n",
    "        analysis = extract_xml(orchestrator_response, \"analysis\")\n",
    "        tasks_xml = extract_xml(orchestrator_response, \"tasks\")\n",
    "        tasks = parse_tasks(tasks_xml)\n",
    "        \n",
    "        print(\"\\n=== ORCHESTRATOR OUTPUT ===\")\n",
    "        print(f\"\\nANALYSIS:\\n{analysis}\")\n",
    "        print(f\"\\nTASKS:\\n{tasks}\")\n",
    "        \n",
    "        # Step 2: Process each task\n",
    "        worker_results = []\n",
    "        for task_info in tasks:\n",
    "            worker_input = self._format_prompt(\n",
    "                self.worker_prompt,\n",
    "                original_task=task,\n",
    "                task_type=task_info['type'],\n",
    "                task_description=task_info['description'],\n",
    "                **context\n",
    "            )\n",
    "            \n",
    "            worker_response = llm_call(worker_input)\n",
    "            result = extract_xml(worker_response, \"response\")\n",
    "            \n",
    "            worker_results.append({\n",
    "                \"type\": task_info[\"type\"],\n",
    "                \"description\": task_info[\"description\"],\n",
    "                \"result\": result\n",
    "            })\n",
    "            \n",
    "            print(f\"\\n=== WORKER RESULT ({task_info['type']}) ===\\n{result}\\n\")\n",
    "        \n",
    "        return {\n",
    "            \"analysis\": analysis,\n",
    "            \"worker_results\": worker_results,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORCHESTRATOR_PROMPT = \"\"\"\n",
    "Analyze this task and break it down into 2-3 distinct approaches:\n",
    "\n",
    "Task: {task}\n",
    "\n",
    "Return your response in this format:\n",
    "\n",
    "<analysis>\n",
    "Explain your understanding of the task and which variations would be valuable.\n",
    "Focus on how each approach serves different aspects of the task.\n",
    "</analysis>\n",
    "\n",
    "<tasks>\n",
    "    <task>\n",
    "    <type>formal</type>\n",
    "    <description>Write a precise, technical version that emphasizes specifications</description>\n",
    "    </task>\n",
    "    <task>\n",
    "    <type>conversational</type>\n",
    "    <description>Write an engaging, friendly version that connects with readers</description>\n",
    "    </task>\n",
    "</tasks>\n",
    "\"\"\"\n",
    "\n",
    "WORKER_PROMPT = \"\"\"\n",
    "Generate content based on:\n",
    "Task: {original_task}\n",
    "Style: {task_type}\n",
    "Guidelines: {task_description}\n",
    "\n",
    "Return your response in this format:\n",
    "\n",
    "<response>\n",
    "Your content here, maintaining the specified style and fully addressing requirements.\n",
    "</response>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "orchestrator = FlexibleOrchestrator(\n",
    "    orchestrator_prompt=ORCHESTRATOR_PROMPT,\n",
    "    worker_prompt=WORKER_PROMPT,\n",
    ")\n",
    "\n",
    "results = orchestrator.process(\n",
    "    task=\"Write a product description for a new eco-friendly water bottle\",\n",
    "    context={\n",
    "        \"target_audience\": \"environmentally conscious millennials\",\n",
    "        \"key_features\": [\"plastic-free\", \"insulated\", \"lifetime warranty\"]\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
